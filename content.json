{"meta":{"title":"Hexo","subtitle":"","description":"This is Bear-blog!!!","author":"John Doe","url":"http://example.com","root":"/"},"pages":[],"posts":[{"title":"Spark基础配置","slug":"Spark基础配置","date":"2022-05-28T07:08:37.447Z","updated":"2022-05-28T06:59:07.027Z","comments":true,"path":"2022/05/28/Spark基础配置/","link":"","permalink":"http://example.com/2022/05/28/Spark%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/","excerpt":"","text":"1.虚拟机分配123node1：192.168.88.151node2：192.168.88.152node3：192.168.88.153 开启虚拟机，连接FinalShell输入以下命令查看主机主机名、host映射、防火墙状态 1cd /etc/hostname 1cd /etc/hosts 1systemctl status firewalld.service 2.安装JDK（1）上传JDK压缩包到export/server/路径下 （2）解压安装包 tar zxvf jdk-8u65-linux-x64.tar.gz 建立软连接 1ln -s /export/server/jdk-8u65-linux-x64/ /export/server/jdk （3）配置环境变量 vim /etc/export 添加以下内容 123export JAVA_HOME=/export/server/jdk1.8.0_24export PATH=$PATH:$JAVA_HOME/binexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib （4）source /etc/profile 使环境变量生效 （5）向node2、node3分发JDK 12scp -r /export/server/jdk1.8.0_241/ root@node2:/export/server/scp -r /export/server/jdk1.8.0_241/ root@node3:/export/server/ （6）向node2、node3复制环境变量 12scp /etc/profile root@node2:/etc/scp /etc/profile root@node3:/etc/ （7）source /etc/profile 使环境变量生效 （8）分别在三台虚拟机执行以下命令检验安装是否成功 1java -version Java(TM) SE Runtime Environment (build 1.8.0_241-b07) Java HotSpot(TM) 64-Bit Server VM (build 25.241-b07, mixed mode) 3.安装配置Hadoop集群(1) 集群角色规划 node1:namenode datanode resourcemanager nodemanager node2: secondarynamenode datanode nodemanager node3: datanode nodemanager (2) 服务器基础环境准备 1vim /etc/hostname Host映射 123192.168.88.151 node1192.168.88.152 node2192.168.88.153 node3 (3) 关闭防火墙（3台机器） 12systemctl stop firewalld.service #关闭防火墙systemctl disable firewalld.service #禁止防火墙自动开启 配置SSH免密登陆 node1生成公钥私钥 (一路回车) 1ssh-keygen 配置免密登录到node1 node2 node3 123ssh-copy-id node1ssh-copy-id node2ssh-copy-id node3 (4) 上传hadoop压缩包到export/server/路径下 解压 1tar -zxvf hadoop-3.3.0-Centos7-64-with-snappy.tar.gz 建立软链接 1ln -s /export/server/ hadoop-3.3.0-Centos7-64 /export/server/hadoop (5) 修改配置文件hadoop-env.sh（配置文件路径 hadoop-3.3.0/etc/hadoop） 添加以下内容： 123456export JAVA_HOME=/export/server/jdk1.8.0_241export HDFS_NAMENODE_USER=rootexport HDFS_DATANODE_USER=rootexport HDFS_SECONDARYNAMENODE_USER=rootexport YARN_RESOURCEMANAGER_USER=rootexport YARN_NODEMANAGER_USER=root (6) 修改配置文件core-site.xml 1234567891011121314151617181920212223242526272829303132 &lt;!-- 设置默认使用的文件系统 Hadoop支持file、HDFS、GFS、ali|Amazon云等文件系统 --&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://node1:8020&lt;/value&gt; &lt;/property&gt; &lt;!-- 设置Hadoop本地保存数据路径 --&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/export/data/hadoop-3.3.0&lt;/value&gt; &lt;/property&gt; &lt;!-- 设置HDFS web UI用户身份 --&gt; &lt;property&gt; &lt;name&gt;hadoop.http.staticuser.user&lt;/name&gt; &lt;value&gt;root&lt;/value&gt; &lt;/property&gt; &lt;!-- 整合hive 用户代理设置 --&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.root.hosts&lt;/name&gt; &lt;value&gt;*&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.root.groups&lt;/name&gt; &lt;value&gt;*&lt;/value&gt; &lt;/property&gt; &lt;!-- 文件系统垃圾桶保存时间 --&gt; &lt;property&gt; &lt;name&gt;fs.trash.interval&lt;/name&gt; &lt;value&gt;1440&lt;/value&gt;&lt;/property&gt; (7) 修改配置文件hdfs-site.xml 添加以下内容： 12345 &lt;!-- 设置SNN进程运行机器位置信息 --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt; &lt;value&gt;node2:9868&lt;/value&gt;&lt;/property&gt; (8) 修改配置文件 mapred-site.xml 添加以下内容： 12345678910111213141516171819202122232425262728293031&lt;!-- 设置MR程序默认运行模式： yarn集群模式 local本地模式 --&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; &lt;!-- MR程序历史服务地址 --&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt; &lt;value&gt;node1:10020&lt;/value&gt; &lt;/property&gt; &lt;!-- MR程序历史服务器web端地址 --&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt; &lt;value&gt;node1:19888&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.app.mapreduce.am.env&lt;/name&gt; &lt;value&gt;HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.map.env&lt;/name&gt; &lt;value&gt;HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.reduce.env&lt;/name&gt; &lt;value&gt;HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;&lt;/value&gt;&lt;/property&gt; (9) 修改配置文件yarn-site.xml 添加以下内容： 12345678910111213141516171819202122232425262728293031323334353637383940&lt;!-- 设置YARN集群主角色运行机器位置 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;node1&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;!-- 是否将对容器实施物理内存限制 --&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.pmem-check-enabled&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;/property&gt; &lt;!-- 是否将对容器实施虚拟内存限制。 --&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;/property&gt; &lt;!-- 开启日志聚集 --&gt; &lt;property&gt; &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;!-- 设置yarn历史服务器地址 --&gt; &lt;property&gt; &lt;name&gt;yarn.log.server.url&lt;/name&gt; &lt;value&gt;http://node1:19888/jobhistory/logs&lt;/value&gt; &lt;/property&gt; &lt;!-- 历史日志保存的时间 7天 --&gt; &lt;property&gt; &lt;name&gt;yarn.log-aggregation.retain-seconds&lt;/name&gt; &lt;value&gt;604800&lt;/value&gt;&lt;/property&gt; (10) 修改配置文件workers 添加以下内容： 123node1.itcast.cnnode2.itcast.cnnode3.itcast.cn (11) 分发同步hadoop安装包 12scp -r hadoop-3.3.0 root@node2:$PWDscp -r hadoop-3.3.0 root@node3:$PWD (12) 将hadoop添加到环境变量 123vim /etc/profileexport HADOOP_HOME=/export/server/hadoop-3.3.0export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin (13) 向node2、node3复制环境变量 123scp /etc/profile root@node2:/etc/scp /etc/profile root@node3:/etc/source /etc/profile #使环境变量生效 (14) Hadoop集群启动 （==首次启动==）格式化namenode 1hdfs namenode -format 脚本一键启动：start-dfs.sh 、start-yarn.sh (15) 访问WEB UI页面验证是否配置成功 HDFS集群：http://node1:9870/ YARN集群：http://node1:8088/ 4.zookeeper集群配置(1) 基本规划 123node1：192.168.88.151 1node2：192.168.88.152 2node3：192.168.88.153 3 (2) 上传zookeeper压缩包export/server/路径下 解压 1tar -zxvf zookeeper-3.4.6.tar.gz 建立软连接 1ln -s /export/server/zookeeper-3.4.6 /export/server/zookeeper (3) 修改配置文件zoo_sample.cfg 123cp zoo_sample.cfg zoo.cfgmkdir -p /export/server/zookeeper/zkdatas/vim zoo.cfg 1234567891011#修改以下内容：#Zookeeper的数据存放目录dataDir=/export/server/zookeeper/zkdatas# 保留多少个快照autopurge.snapRetainCount=3# 日志多少小时清理一次autopurge.purgeInterval=1# 集群中服务器地址server.1=node1:2888:3888server.2=node2:2888:3888server.3=node3:2888:3888 (4)添加myid配置 1echo 1 &gt; /export/server/zookeeper/zkdatas/myid (5) 分发安装包并修改myid值 123cd /export/server/scp -r /export/server/zookeeper-3.4.6/ node2:$PWDscp -r /export/server/zookeeper-3.4.6/ node3:$PWD 第二台机器上建立软连接, 并修改myid的值为2 123cd /export/server/ln -s zookeeper-3.4.6/ zookeeper echo 2 &gt; /export/server/zookeeper/zkdatas/myid 第三台机器上建立软连接, 并修改myid的值为3 123cd /export/server/ln -s zookeeper-3.4.6/ zookeeper echo 3 &gt; /export/server/zookeeper/zkdatas/myid (6) 配置环境变量 123vim /etc/profile export ZOOKEEPER_HOME=/export/server/zookeeperexport PATH=$PATH:$ZOOKEEPER_HOME/bin (7) 向node2、node3复制环境变量 123scp /etc/profile root@node2:/etc/scp /etc/profile root@node3:/etc/source /etc/profile #使环境变量生效 (8) 三台机器启动zookeeper服务 12/export/server/zookeeper/bin/zkServer.sh start/export/server/zookeeper/bin/zkServer.sh stop (9) 查看服务状态 12/export/server/zookeeper/bin/zkServer.sh status","categories":[],"tags":[]},{"title":"Spark全流程配置","slug":"Spark全流程配置","date":"2022-05-22T08:11:29.000Z","updated":"2022-05-28T06:53:48.104Z","comments":true,"path":"2022/05/22/Spark全流程配置/","link":"","permalink":"http://example.com/2022/05/22/Spark%E5%85%A8%E6%B5%81%E7%A8%8B%E9%85%8D%E7%BD%AE/","excerpt":"","text":"一．基础环境 导入三台虚拟机，三台虚拟机信息汇总。 主机名 Node1.itcast.cn Node2.itcast.cn Node3.itcast.cn IP 192.168.88.151 192.168.88.152 192.168.88.153 用户名、密码 root/123456 root/123456 root/123456 集群角色规划 服务器 运行角色 Node1.itcast.cn Namenode(主角色)，Datanode(从角色)，Resourcemanager(主角色)Nodemanager(从角色)，master，follower，worker，QuorumPeerMain,sparksubmit Node2.itcast.cn Secondarynamenode(主角色辅助角色)，datanode(从角色)Nodemanager(从角色)，worker，leader Node3.itcast.cn Datanode(从角色)，nodemanager(从角色)，worker，follower （1）主机hosts映射： （2）关闭防火墙 （3）同步时间：ntpdate ntp5.aliyun.com （4）配置ssh 免密登录node1、2、3 二、安装并配置JDK （1）编译环境软件安装目录 （2）上传 jdk-8u171-linux-x64.tar.gz到/export/softwares/目录下 安装JDK 解压文件至/export/servers/ JDK安装目录重命名为jdk （3）配置环境变量 重新加载环境变量文件 （4）JDK环境验证 （5）分发JDK相关文件到node2、3 1.jdk相关文件分发 123scp -r /export/servers/jdk1.8.0_171/ root@slave1:/export/servers/ scp -r /export/servers/jdk1.8.0_171/ root@slave2:/export/servers/ 2.分发系统环境变量文件至slave1,slave2 123scp -r /etc/profile root@slave1:/etc/profile scp -r /etc/profile root@slave2:/etc/profile 3.分别在slave1、slave2上执行source /etc/profile使环境变量生效 三、Hadoop集群的安装和配置 1.把 hadoop-3.3.0-Centos7-64-with-snappy.tar.gz 上传到 /export/server 并解压文件 1tar -zxvf hadoop-3.3.0-Centos7-64-with-snappy.tar.gz 2.修改配置文件(进入路径 /export/server/hadoop-3.3.0/etc/hadoop) 1cd /export/server/hadoop-3.3.0/etc/hadoop 3.hadoop-env.sh 12345678#文件最后添加export JAVA_HOME=/export/server/jdk1.8.0_241export HDFS_NAMENODE_USER=rootexport HDFS_DATANODE_USER=rootexport HDFS_SECONDARYNAMENODE_USER=rootexport YARN_RESOURCEMANAGER_USER=rootexport YARN_NODEMANAGER_USER=root 4.core-site.xml 12345678910111213141516171819202122232425262728293031323334&lt;!-- 设置默认使用的文件系统 Hadoop支持file、HDFS、GFS、ali|Amazon云等文件系统 --&gt;&lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://master:8020&lt;/value&gt;&lt;/property&gt;&lt;!-- 设置Hadoop本地保存数据路径 --&gt;&lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/export/data/hadoop-3.3.0&lt;/value&gt;&lt;/property&gt;&lt;!-- 设置HDFS web UI用户身份 --&gt;&lt;property&gt; &lt;name&gt;hadoop.http.staticuser.user&lt;/name&gt; &lt;value&gt;root&lt;/value&gt;&lt;/property&gt;&lt;!-- 整合hive 用户代理设置 --&gt;&lt;property&gt; &lt;name&gt;hadoop.proxyuser.root.hosts&lt;/name&gt; &lt;value&gt;*&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hadoop.proxyuser.root.groups&lt;/name&gt; &lt;value&gt;*&lt;/value&gt;&lt;/property&gt;&lt;!-- 文件系统垃圾桶保存时间 --&gt;&lt;property&gt; &lt;name&gt;fs.trash.interval&lt;/name&gt; &lt;value&gt;1440&lt;/value&gt;&lt;/property&gt; 4.hdfs-site.xml 12345&lt;!-- 设置SNN进程运行机器位置信息 --&gt;&lt;property&gt; &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt; &lt;value&gt;slave1:9868&lt;/value&gt;&lt;/property&gt; 5.mapred-site.xml 1234567891011121314151617181920212223242526272829303132&lt;!-- 设置MR程序默认运行模式： yarn集群模式 local本地模式 --&gt;&lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt;&lt;/property&gt;&lt;!-- MR程序历史服务地址 --&gt;&lt;property&gt; &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt; &lt;value&gt;master:10020&lt;/value&gt;&lt;/property&gt; &lt;!-- MR程序历史服务器web端地址 --&gt;&lt;property&gt; &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt; &lt;value&gt;master:19888&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;yarn.app.mapreduce.am.env&lt;/name&gt; &lt;value&gt;HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;mapreduce.map.env&lt;/name&gt; &lt;value&gt;HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;mapreduce.reduce.env&lt;/name&gt; &lt;value&gt;HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;&lt;/value&gt;&lt;/property&gt; 6.yarn-site.xml 12345678910111213141516171819202122232425262728293031323334353637383940&lt;!-- 设置YARN集群主角色运行机器位置 --&gt;&lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;master&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt;&lt;/property&gt;&lt;!-- 是否将对容器实施物理内存限制 --&gt;&lt;property&gt; &lt;name&gt;yarn.nodemanager.pmem-check-enabled&lt;/name&gt; &lt;value&gt;false&lt;/value&gt;&lt;/property&gt;&lt;!-- 是否将对容器实施虚拟内存限制。 --&gt;&lt;property&gt; &lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt; &lt;value&gt;false&lt;/value&gt;&lt;/property&gt;&lt;!-- 开启日志聚集 --&gt;&lt;property&gt; &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt; &lt;value&gt;true&lt;/value&gt;&lt;/property&gt;&lt;!-- 设置yarn历史服务器地址 --&gt;&lt;property&gt; &lt;name&gt;yarn.log.server.url&lt;/name&gt; &lt;value&gt;http://master:19888/jobhistory/logs&lt;/value&gt;&lt;/property&gt;&lt;!-- 历史日志保存的时间 7天 --&gt;&lt;property&gt; &lt;name&gt;yarn.log-aggregation.retain-seconds&lt;/name&gt; &lt;value&gt;604800&lt;/value&gt;&lt;/property&gt; 7.workers 123masterslave1slave2 8.分发同步hadoop安装包 1234cd /export/serverscp -r hadoop-3.3.0 root@slave1:$PWDscp -r hadoop-3.3.0 root@slave2:$PWD 9.将hadoop添加到环境变量 1234vim /etc/profileexport HADOOP_HOME=/export/server/hadoop-3.3.0export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin 10.重新加载环境变量文件 1source /etc/profile Hadoop集群启动 格式化namenode（只有首次启动需要格式化） 1hdfs namenode -format （1）脚本一键启动 12345678910111213[root@master ~]# start-dfs.sh Starting namenodes on [master]上一次登录：五 3月 11 21:27:24 CST 2022pts/0 上Starting datanodes上一次登录：五 3月 11 21:27:32 CST 2022pts/0 上Starting secondary namenodes [slave1]上一次登录：五 3月 11 21:27:35 CST 2022pts/0 上[root@master ~]# start-yarn.sh Starting resourcemanager上一次登录：五 3月 11 21:27:41 CST 2022pts/0 上Starting nodemanagers上一次登录：五 3月 11 21:27:51 CST 2022pts/0 上 （2）启动后，输入jps查看 1234567891011121314151617[root@master ~]# jps127729 NameNode127937 DataNode14105 Jps128812 NodeManager128591 ResourceManager[root@slave1 hadoop]# jps121889 NodeManager121559 SecondaryNameNode7014 Jps121369 DataNode[root@slave2 hadoop]# jps6673 Jps121543 NodeManager121098 DataNode WEB页面 HDFS集群 1http://master:9870/ YARN集群 1http://master:8088/","categories":[],"tags":[]},{"title":"Hello World","slug":"hello-world","date":"2022-05-16T14:28:24.163Z","updated":"2022-05-16T14:27:05.752Z","comments":true,"path":"2022/05/16/hello-world/","link":"","permalink":"http://example.com/2022/05/16/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}],"categories":[],"tags":[]}